"""
Enhanced Astro Agent - æ•´åˆLangGraph ReActAgent + MCPå·¥å…· + RAGæª¢ç´¢
åŸºæ–¼é–‹ç™¼è¨ˆåŠƒå¯¦ç¾æ™ºèƒ½å æ˜ŸåŠ©æ‰‹çš„æ ¸å¿ƒAgenté‚è¼¯
"""

import json
import asyncio
import os
from typing import List, Dict, Any, AsyncGenerator
from pathlib import Path

# LangGraph and LangChain imports
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from langchain_openai import AzureChatOpenAI
from langchain.callbacks.tracers import LangChainTracer 
# MCP adapter imports
try:
    from langchain_mcp_adapters.client import MultiServerMCPClient
except ImportError:
    print("Warning: langchain-mcp-adapters not available, MCP tools disabled")
    MultiServerMCPClient = None

# Local imports
from .tools.rag_tool import get_rag_tools
from .client.pinecone_client import PineconeClient
from .tools.natal_tool import natal_figure


class EnhancedAstroAgent:
    """
    å¢å¼·å‹å æ˜ŸAgent
    æ•´åˆLangGraph ReActAgentã€MCPå·¥å…·å’ŒRAGæª¢ç´¢åŠŸèƒ½
    """
    
    def __init__(self):
        """åˆå§‹åŒ–Enhanced Astro Agent"""
        self.agent = None
        self.llm = None
        self.mcp_client = None
        self.rag_tools = []
        self.system_prompt = ""
        self.pinecone_client = PineconeClient()
        self.tracer = LangChainTracer(project_name="test")
        # è¼‰å…¥ç³»çµ±æç¤º
        self._load_system_prompt()
        
    def _load_system_prompt(self):
        """è¼‰å…¥astrology_mcp.jsonç³»çµ±æç¤º"""
        try:
            prompt_path = os.path.join(os.path.dirname(__file__), "prompts", "astrology_mcp.json")
            with open(prompt_path, "r", encoding="utf-8") as file:
                loaded_data = json.load(file)
                self.system_prompt = json.dumps(loaded_data, ensure_ascii=False, indent=2)
                print(f"âœ… ç³»çµ±æç¤ºè¼‰å…¥æˆåŠŸ: {len(self.system_prompt)} å­—ç¬¦")
        except Exception as e:
            print(f"Warning: Failed to load astrology_mcp.json: {e}")
            self.system_prompt = "You are a professional astrologer assistant."
    
    async def initialize(self):
        """åˆå§‹åŒ–Agentå’Œæ‰€æœ‰å·¥å…·"""
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–Enhanced Astro Agent...")
        
        # 1. åˆå§‹åŒ–LLM
        await self._initialize_llm()
        
        # 2. åˆå§‹åŒ–MCPå·¥å…·
        await self._initialize_mcp_tools()
        
        # 3. åˆå§‹åŒ–RAGå·¥å…·
        self._initialize_rag_tools()
        
        # 4. å‰µå»ºReActAgent
        await self._create_react_agent()
        
        print("âœ… Enhanced Astro Agent åˆå§‹åŒ–å®Œæˆï¼")
    
    async def _initialize_llm(self):
        """åˆå§‹åŒ–èªè¨€æ¨¡å‹"""
        try:
            # ä½¿ç”¨Azure OpenAIä½œç‚ºLangGraphçš„LLM
            self.llm = AzureChatOpenAI(
                azure_endpoint=os.getenv("AZURE_API_END", "https://x7048-m50qpz5s-eastus2.cognitiveservices.azure.com/"),
                api_key=os.getenv("AZURE_API_KEY"),
                api_version="2025-01-01-preview",
                azure_deployment="gpt-4.1",
                temperature=0.7,
                max_tokens=4096
            )
            print("âœ… LLM åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ LLM åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def _initialize_mcp_tools(self):
        """åˆå§‹åŒ–MCPå·¥å…·"""
        if MultiServerMCPClient is None:
            print("âš ï¸ MCPå·¥å…·ä¸å¯ç”¨ï¼Œè·³éMCPåˆå§‹åŒ–")
            return

        try:
            # æª¢æŸ¥å¯ç”¨çš„MCPå·¥å…·
            available_tools = {}

            # æª¢æŸ¥web-searchå·¥å…·
            web_search_path = Path(os.path.join(os.path.dirname(__file__), "MCP", "web-search", "build", "index.js"))
            if web_search_path.exists() and os.getenv("SEARCH_API_KEY"):
                available_tools["web_search"] = {
                    "command": "node",
                    "args": [str(web_search_path.absolute())],
                    "transport": "stdio",
                    "env": {
                        "SEARCH_API_KEY": os.getenv("SEARCH_API_KEY", "")
                    }
                }
                print(f"âœ… ç™¼ç¾web-searchå·¥å…·: {web_search_path}")
            else:
                print("âš ï¸ web-searchå·¥å…·ä¸å¯ç”¨ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨æˆ–ç¼ºå°‘APIå¯†é‘°ï¼‰")

            # æª¢æŸ¥AstroMCPå·¥å…·ï¼ˆä½¿ç”¨æ§‹å»ºå¾Œçš„æ–‡ä»¶ï¼‰
            astro_dist_path = Path(os.path.join(os.path.dirname(__file__), "MCP", "AstroMCP", "dist", "main.js"))
            if astro_dist_path.exists():
                available_tools["astro_mcp"] = {
                    "command": "node",
                    "args": [str(astro_dist_path.absolute())],
                    "transport": "stdio"
                }
                print(f"âœ… ç™¼ç¾AstroMCPå·¥å…·: {astro_dist_path}")
            else:
                astro_src_path = Path(os.path.join(os.path.dirname(__file__), "MCP", "AstroMCP", "index.ts"))
                if astro_src_path.exists():
                    print("âš ï¸ AstroMCPæºæ–‡ä»¶å­˜åœ¨ä½†æœªæ§‹å»ºï¼Œè«‹é‹è¡Œ: cd backend/agents/MCP/AstroMCP && npm run build")
                else:
                    print("âš ï¸ AstroMCPå·¥å…·ä¸å¯ç”¨")

            # # æª¢æŸ¥Natal MCPå·¥å…·ï¼ˆPythonï¼‰
            # natal_mcp_path = Path("natal_mcp/run.py")
            # venv_python = Path("venv312/Scripts/python.exe")
            # if natal_mcp_path.exists() and venv_python.exists():
            #     available_tools["natal_mcp"] = {
            #         "command": str(venv_python.absolute()),
            #         "args": [str(natal_mcp_path.absolute())],
            #         "transport": "stdio"
            #     }
            #     print(f"âœ… ç™¼ç¾Natal MCPå·¥å…·: {natal_mcp_path}")
            # else:
            #     if not natal_mcp_path.exists():
            #         print("âš ï¸ Natal MCPå·¥å…·ä¸å¯ç”¨ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨ï¼‰")
            #     if not venv_python.exists():
            #         print("âš ï¸ Python 3.12è™›æ“¬ç’°å¢ƒä¸å¯ç”¨")

            if available_tools:
                # åˆå§‹åŒ–MCPå®¢æˆ¶ç«¯
                self.mcp_client = MultiServerMCPClient(available_tools)
                print(f"âœ… MCPå·¥å…·åˆå§‹åŒ–æˆåŠŸï¼Œè¼‰å…¥ {len(available_tools)} å€‹å·¥å…·")
            else:
                print("âš ï¸ æ²’æœ‰å¯ç”¨çš„MCPå·¥å…·ï¼Œä½¿ç”¨RAGæ¨¡å¼")
                self.mcp_client = None

        except Exception as e:
            print(f"âš ï¸ MCPå·¥å…·åˆå§‹åŒ–å¤±æ•—: {e}")
            self.mcp_client = None
    
    def _initialize_rag_tools(self):
        """åˆå§‹åŒ–RAGå·¥å…·å’Œæ˜Ÿåœ–å·¥å…·"""
        try:
            # è¼‰å…¥RAGå·¥å…·
            self.rag_tools = get_rag_tools()

            # æ·»åŠ natal chartå·¥å…·
            self.rag_tools.append(natal_figure)

            # è¼‰å…¥æ˜Ÿåœ–ç”Ÿæˆå·¥å…·
            # self.rag_tools.extend(chart_tools)

            print(f"âœ… RAGå’Œæ˜Ÿåœ–å·¥å…·åˆå§‹åŒ–æˆåŠŸï¼Œè¼‰å…¥ {len(self.rag_tools)} å€‹å·¥å…·")
        except Exception as e:
            print(f"âš ï¸ RAGå·¥å…·åˆå§‹åŒ–å¤±æ•—: {e}")
            self.rag_tools = []
    
    async def _create_react_agent(self):
        """å‰µå»ºLangGraph ReActAgent"""
        try:
            # æ”¶é›†æ‰€æœ‰å·¥å…·
            all_tools = []
            
            # æ·»åŠ RAGå·¥å…·
            all_tools.extend(self.rag_tools)
            
            # æ·»åŠ MCPå·¥å…·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.mcp_client:
                try:
                    mcp_tools = await self.mcp_client.get_tools()
                    all_tools.extend(mcp_tools)
                    print(f"âœ… è¼‰å…¥ {len(mcp_tools)} å€‹MCPå·¥å…·")
                except Exception as e:
                    print(f"âš ï¸ ç„¡æ³•è¼‰å…¥MCPå·¥å…·: {e}")
            
            # å‰µå»ºReActAgent
            if all_tools:
                self.agent = create_react_agent(
                    model=self.llm, 
                    tools=all_tools,
                    prompt=self.system_prompt
                )
                print(f"âœ… ReActAgentå‰µå»ºæˆåŠŸï¼Œç¸½å…± {len(all_tools)} å€‹å·¥å…·")
            else:
                print("âš ï¸ æ²’æœ‰å¯ç”¨å·¥å…·ï¼Œå‰µå»ºåŸºç¤Agent")
                self.agent = create_react_agent(
                    model=self.llm, 
                    tools=[],
                    prompt=self.system_prompt
                )
                
        except Exception as e:
            print(f"âŒ ReActAgentå‰µå»ºå¤±æ•—: {e}")
            raise
    
    async def astream(self, user_input: str, include_rag: bool = True) -> AsyncGenerator[str, None]:
        """
        æµå¼è™•ç†ç”¨æˆ¶æŸ¥è©¢
        
        Args:
            user_input (str): ç”¨æˆ¶è¼¸å…¥
            include_rag (bool): æ˜¯å¦åŒ…å«RAGæª¢ç´¢
            
        Yields:
            str: SSEæ ¼å¼çš„æµå¼å›æ‡‰
        """
        if not self.agent:
            yield f"data: {json.dumps({'type': 'error', 'message': 'Agentæœªåˆå§‹åŒ–'}, ensure_ascii=False)}\n\n"
            return
            
        try:
            # å¯é¸çš„RAGæª¢ç´¢
            rag_context = []
            if include_rag:
                rag_context = await self._get_rag_context(user_input)
                if rag_context:
                    yield f"data: {json.dumps({'type': 'rag_context', 'context': rag_context}, ensure_ascii=False)}\n\n"
            
            # ä½¿ç”¨ReActAgentæµå¼è™•ç†æŸ¥è©¢
            message = HumanMessage(content=user_input)
            
            async for event in self.agent.astream_events(
                {"messages": [message]},
                config={"callbacks": [self.tracer]},
                version="v1",
            ):
                kind = event["event"]
                if kind == "on_chat_model_stream":
                    chunk_data = event["data"].get("chunk")
                    if chunk_data and hasattr(chunk_data, "content"):
                        content = chunk_data.content or ""
                        if content:
                            yield f"data: {json.dumps({'chunk': content}, ensure_ascii=False)}\n\n"
                            
                elif kind == "on_chat_model_start":
                    # é–‹å§‹æ–°çš„å›æ‡‰
                    if not hasattr(self, "_first_model_start_skipped"):
                        self._first_model_start_skipped = True
                    else:
                        yield f"data: {json.dumps({'type': 'start_response', 'content': ''}, ensure_ascii=False)}\n\n"
                        
                elif kind == "on_tool_start":
                    tool_id = event["run_id"]
                    tool_name = event["name"]
                    tool_args = event["data"].get("input")
                    yield f"data: {json.dumps({'role': 'ai', 'type': 'tool_use', 'tool_id': tool_id, 'tool_name': tool_name, 'tool_args': tool_args, 'content': f'æ­£åœ¨ä½¿ç”¨å·¥å…· {tool_name}...'}, ensure_ascii=False)}\n\n"
                    
                elif kind == "on_tool_end":
                    tool_id = event["run_id"]  
                    tool_name = event["name"]
                    tool_result = event["data"].get("output")
                    result_content = tool_result.content if hasattr(tool_result, 'content') else str(tool_result)
                    yield f"data: {json.dumps({'role': 'ai', 'type': 'tool_result', 'tool_name': tool_name, 'tool_id': tool_id, 'tool_result': result_content}, ensure_ascii=False)}\n\n"
                    
        except Exception as e:
            print(f"âŒ æµå¼æŸ¥è©¢è™•ç†å¤±æ•—: {e}")
            yield f"data: {json.dumps({'type': 'error', 'message': f'è™•ç†æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}'}, ensure_ascii=False)}\n\n"
    
    async def _get_rag_context(self, query: str) -> List[Dict]:
        """ç²å–RAGä¸Šä¸‹æ–‡"""
        try:
            return self.pinecone_client.search_rag_context(
                user_query=query,
                index_name="astrology-text",
                namespace="hierarchy_chunking_strategy",
                top_k=5
            )
        except Exception as e:
            print(f"âš ï¸ RAGæª¢ç´¢å¤±æ•—: {e}")
            return []
    

    
    def get_agent_info(self) -> Dict[str, Any]:
        """ç²å–Agentè³‡è¨Š"""
        return {
            "agent_initialized": self.agent is not None,
            "llm_available": self.llm is not None,
            "mcp_available": self.mcp_client is not None,
            "rag_tools_count": len(self.rag_tools),
            "system_prompt_loaded": bool(self.system_prompt)
        }


# å…¨å±€Agentå¯¦ä¾‹
_enhanced_agent = None


async def get_enhanced_agent() -> EnhancedAstroAgent:
    """ç²å–å…¨å±€Enhanced Astro Agentå¯¦ä¾‹"""
    global _enhanced_agent
    if _enhanced_agent is None:
        _enhanced_agent = EnhancedAstroAgent()
        await _enhanced_agent.initialize()
    return _enhanced_agent


async def initialize_agent() -> EnhancedAstroAgent:
    """åˆå§‹åŒ–Agentï¼ˆå¼·åˆ¶é‡æ–°åˆå§‹åŒ–ï¼‰"""
    global _enhanced_agent
    _enhanced_agent = EnhancedAstroAgent()
    await _enhanced_agent.initialize()
    return _enhanced_agent


if __name__ == "__main__":
    # æ¸¬è©¦Agentæµå¼è¼¸å‡º
    async def test_agent_stream():
        print("ğŸ§ª æ¸¬è©¦Enhanced Astro Agent æµå¼è¼¸å‡º...")
        
        agent = await initialize_agent()
        
        # æ¸¬è©¦æŸ¥è©¢
        test_queries = [
            "è«‹å¹«æˆ‘åˆ†æ2000å¹´1æœˆ18æ—¥ä¸‹åˆ7é»åœ¨å°åŒ—å‡ºç”Ÿçš„æ˜Ÿç›¤"
        ]
        
        for query in test_queries:
            print(f"\nğŸ“ æŸ¥è©¢ï¼š{query}")
            print("ğŸ”„ é–‹å§‹æµå¼å›æ‡‰ï¼š")
            print("-" * 50)
            
            # # ä½¿ç”¨æµå¼è™•ç†
            # async for chunk in agent.astream(query):
            #     print(chunk, end="", flush=True)
            
            # print("\n" + "-" * 50)
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(test_agent_stream())
